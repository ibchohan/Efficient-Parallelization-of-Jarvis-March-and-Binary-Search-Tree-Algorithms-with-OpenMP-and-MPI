# Efficient Parallelization of Jarvis March and Binary Search Tree Algorithms with OpenMP and MPI

## Introduction

This project focuses on two main areas:

1. **Optimizing Jarvis March: A Parallel vs. Serial Approach**: Jarvis March, also known as the Gift-Wrapping algorithm, is a convex hull algorithm used in computational geometry. The algorithm efficiently computes the convex hull of a set of points in a plane. Our project aims to compare the efficiencies of these implementations. Through an analysis of execution times, scalability, and resource utilization, our investigation aims to highlight the advantages and challenges associated with parallelizing the Jarvis March algorithm.

2. **Binary Search Tree: A Parallel vs. Serial Approach**: A binary search tree (BST) is a hierarchical data structure where each node has a key, and values in the left subtree are smaller while those in the right subtree are larger. We analyze the performance distinctions between traditional serial BST structures and their parallelized counterparts. Examining factors like search times, scalability, and resource utilization, our study unveils the advantages and challenges in parallelizing Binary Search Tree implementation.

## Methodology

The methodology for this project includes the following steps:

- Binary Search Tree Pseudocode
- Searching in Binary Search Tree (BST)
- Jarvis March Serial Algorithm- A convex Hull solution
- Jarvis March using MPI

## Performance Comparison (OpenMP vs MPI)

The performance comparison between OpenMP and MPI for both Jarvis March Algorithm and Binary Search Tree is included in the project.

## Conclusion

In conclusion, we synthesize our findings from the parallelization efforts on the Jarvis March algorithm and Binary Search Tree. By summarizing the advantages and challenges uncovered during the performance comparisons using OpenMP and MPI, we aim to provide a comprehensive understanding of the implications for computational geometry and data structure management in parallel and distributed computing scenarios. The conclusion will also outline potential avenues for future research and applications of parallel computing techniques in similar algorithms and data structures.
